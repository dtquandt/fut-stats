{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Part 1: Getting Player URLs\n",
    "\n",
    "## Context\n",
    "\n",
    "The goal of the FUT-Stats project is to run analyses to better understand the FIFA Ultimate Team market and economy, but that requires data. There is no official data source from EA for FUT, but the player-run website FUTBin has become the de facto source for player and pricing data from the game.\n",
    "\n",
    "However, there is also no official FUTBin-sanctioned way to acquire their data in a form that we can easily work with, so we'll have to scrape it from the website. For the most part, the plan is to use Scrapy to do this, fetching data from each player into a database we can then work from.\n",
    "\n",
    "The first step is to page through the player list and get the URLs for every player card. We could do this in Scrapy along with all of the other steps, but it's an opportunity for showing how more basic web scraping with the requests and Beautiful Soup libraries works.\n",
    "\n",
    "The goal for this notebook is to hopefully, by the end, have a saved list of every player URL on the Futbin platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the website\n",
    "\n",
    "Before we write even a single line of code, we need to have a look at the website and see what information we want and where it's located. Let's load up futbin.com.  \n",
    "  \n",
    "  \n",
    "  \n",
    "### Homepage\n",
    "![](img/futbin_homepage.png)  \n",
    "\n",
    "\n",
    "### Player directory\n",
    "![](img/futbin_playerdirectory.png)  \n",
    "\n",
    "\n",
    "### Player page\n",
    "![](img/futbin_player.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a plan\n",
    "\n",
    "Essentially, what we want to do is open the player directory, page through the players so we collect every single URL, and then collect as much information we can about them from their individual page. We could do this a few different ways. One of them is to use a spider-like approach, where our crawler goes through each page and \"clicks\" on each player, collecting data along the way.\n",
    "\n",
    "Another is to first collect every player URL and then run another scraper over that list to collect player information.\n",
    "\n",
    "Both approaches have their advantages. The first is harder to build but easier to run, since it does everything in a single step. The second is easier to build and more robust against being blocked by the server, since it can be batched more easily.\n",
    "\n",
    "Since we want to show the code directly in the notebook we're going to use the second approach, which we can run using the simpler syntax of requests and bs4, as opposed to Scrapy, which has a more complex object-oriented approach to building webscrapers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is make sure the page we want to scrape is actually accessible by our code. The way the requests library work is quite simple - an HTTP request is made to the URL you supply and the response is saved as an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_url = 'https://www.futbin.com/players'\n",
    "res = requests.get(players_url)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 200 response means OK, so the script was able to fetch the webpage without further issues. Sometimes, you may need to specify custom headers and cookies to avoid being blocked by the target server. \n",
    "\n",
    "The .text and .content attributes can be used on the response object to look at the HTML returned by the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277313"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we can see, quite a lot of HTML was returned - this is the code that makes up the page you see in your browser.\n",
    "len(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting HTML to find the player URLs\n",
    "![](img/futbin_table_inspect.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding elements with selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "results = soup.find_all('a', class_='player_name_players_table')\n",
    "\n",
    "for result in results:\n",
    "    player_urls.append(f\"https://futbin.com{result['href']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://futbin.com/20/player/44079/lionel-messi',\n",
       " 'https://futbin.com/20/player/44085/virgil-van-dijk',\n",
       " 'https://futbin.com/20/player/44119/cristiano-ronaldo',\n",
       " 'https://futbin.com/20/player/45418/diego-maradona',\n",
       " 'https://futbin.com/20/player/45488/pele',\n",
       " 'https://futbin.com/20/player/48190/kevin-de-bruyne',\n",
       " 'https://futbin.com/20/player/48196/virgil-van-dijk',\n",
       " 'https://futbin.com/20/player/48243/lionel-messi',\n",
       " 'https://futbin.com/20/player/48290/robert-lewandowski',\n",
       " 'https://futbin.com/20/player/48350/cristiano-ronaldo',\n",
       " 'https://futbin.com/20/player/1/pele',\n",
       " 'https://futbin.com/20/player/44081/kylian-mbappe',\n",
       " 'https://futbin.com/20/player/44089/kevin-de-bruyne',\n",
       " 'https://futbin.com/20/player/48193/sadio-mane',\n",
       " 'https://futbin.com/20/player/48395/kylian-mbappe',\n",
       " 'https://futbin.com/20/player/48403/neymar-jr',\n",
       " 'https://futbin.com/20/player/2/diego-maradona',\n",
       " 'https://futbin.com/20/player/44080/sadio-mane',\n",
       " 'https://futbin.com/20/player/44082/alisson',\n",
       " 'https://futbin.com/20/player/44087/n-golo-kante',\n",
       " 'https://futbin.com/20/player/45417/ronaldo',\n",
       " 'https://futbin.com/20/player/45529/zinedine-zidane',\n",
       " 'https://futbin.com/20/player/47617/lionel-messi',\n",
       " 'https://futbin.com/20/player/48096/lionel-messi',\n",
       " 'https://futbin.com/20/player/48197/alisson',\n",
       " 'https://futbin.com/20/player/48198/mohamed-salah',\n",
       " 'https://futbin.com/20/player/48233/raphael-varane',\n",
       " 'https://futbin.com/20/player/48238/karim-benzema',\n",
       " 'https://futbin.com/20/player/48245/luis-suarez',\n",
       " 'https://futbin.com/20/player/48287/timo-werner']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the \"next page\" button\n",
    "![](img/futbin_next_inspect.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://futbin.com/players?page=2\n"
     ]
    }
   ],
   "source": [
    "next_button = soup.find_all('a', attrs={'aria-label': 'Next'})[0]\n",
    "next_url = f\"https://futbin.com{next_button['href']}\"\n",
    "print(next_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if it's the last page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_page_res = requests.get('https://www.futbin.com/20/players?page=754')\n",
    "last_page_soup = bs4.BeautifulSoup(last_page_res.text)\n",
    "last_page_soup.find_all('a', attrs={'aria-label': 'Next'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding cookies and headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def scrape_player_urls(url, player_urls, verbose=True, sleep_min=500, sleep_max=1000):\n",
    "    \n",
    "    cookies = {\n",
    "        '__cfduid': 'da7fb59c676afaf8e9241118df829015a1591911739',\n",
    "        'PHPSESSID': '9m1l5qrjvooidbuu4hl39qkppq',\n",
    "        'theme_player': 'true',\n",
    "        'comments': 'true',\n",
    "        'platform': 'ps4',\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en,en-US;q=0.7,pt-BR;q=0.3',\n",
    "        'DNT': '1',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'TE': 'Trailers',\n",
    "    }\n",
    "\n",
    "    sleep_time = random.randrange(sleep_min, sleep_max)\n",
    "    time.sleep(sleep_time/100)\n",
    "    \n",
    "    base_url = 'https://futbin.com'\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Scraping {url}...')\n",
    "\n",
    "    res = requests.get(url, headers=headers, cookies=cookies)\n",
    "    if res.status_code != 200:\n",
    "        print(f'Error code {res.status_code} when requesting {url}. Waiting one minute to retry.')\n",
    "        time.sleep(60)\n",
    "        res = requests.get(url, headers=headers, cookies=cookies)\n",
    "        if res.status_code != 200:\n",
    "            print(f'Request failed for a second time. Aborting and returning early.')\n",
    "            return player_urls\n",
    "\n",
    "    soup = bs4.BeautifulSoup(res.text, 'lxml')\n",
    "    players = soup.find_all('a', class_='player_name_players_table')\n",
    "    for player in players:\n",
    "        player_urls.append(base_url + player['href'])\n",
    "\n",
    "    next_button_search = soup.find_all('a', attrs={'aria-label': 'Next'})\n",
    "    if next_button_search:\n",
    "        next_button = next_button_search[0]\n",
    "        next_url = base_url + next_button['href'] \n",
    "        return scrape_player_urls(next_url, player_urls)\n",
    "    else:\n",
    "        return player_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.futbin.com/players?page=579...\n",
      "Scraping https://futbin.com/players?page=580...\n",
      "Scraping https://futbin.com/players?page=581...\n",
      "Scraping https://futbin.com/players?page=582...\n",
      "Scraping https://futbin.com/players?page=583...\n",
      "Scraping https://futbin.com/players?page=584...\n",
      "Scraping https://futbin.com/players?page=585...\n",
      "Scraping https://futbin.com/players?page=586...\n",
      "Scraping https://futbin.com/players?page=587...\n",
      "Scraping https://futbin.com/players?page=588...\n",
      "Scraping https://futbin.com/players?page=589...\n",
      "Scraping https://futbin.com/players?page=590...\n",
      "Scraping https://futbin.com/players?page=591...\n",
      "Scraping https://futbin.com/players?page=592...\n",
      "Scraping https://futbin.com/players?page=593...\n",
      "Scraping https://futbin.com/players?page=594...\n",
      "Scraping https://futbin.com/players?page=595...\n",
      "Scraping https://futbin.com/players?page=596...\n",
      "Scraping https://futbin.com/players?page=597...\n",
      "Scraping https://futbin.com/players?page=598...\n",
      "Scraping https://futbin.com/players?page=599...\n",
      "Scraping https://futbin.com/players?page=600...\n",
      "Scraping https://futbin.com/players?page=601...\n",
      "Scraping https://futbin.com/players?page=602...\n",
      "Scraping https://futbin.com/players?page=603...\n",
      "Scraping https://futbin.com/players?page=604...\n",
      "Scraping https://futbin.com/players?page=605...\n",
      "Scraping https://futbin.com/players?page=606...\n",
      "Scraping https://futbin.com/players?page=607...\n",
      "Scraping https://futbin.com/players?page=608...\n",
      "Scraping https://futbin.com/players?page=609...\n",
      "Scraping https://futbin.com/players?page=610...\n",
      "Scraping https://futbin.com/players?page=611...\n",
      "Scraping https://futbin.com/players?page=612...\n",
      "Scraping https://futbin.com/players?page=613...\n",
      "Scraping https://futbin.com/players?page=614...\n",
      "Scraping https://futbin.com/players?page=615...\n",
      "Scraping https://futbin.com/players?page=616...\n",
      "Scraping https://futbin.com/players?page=617...\n",
      "Scraping https://futbin.com/players?page=618...\n",
      "Scraping https://futbin.com/players?page=619...\n",
      "Scraping https://futbin.com/players?page=620...\n",
      "Scraping https://futbin.com/players?page=621...\n",
      "Scraping https://futbin.com/players?page=622...\n",
      "Scraping https://futbin.com/players?page=623...\n",
      "Scraping https://futbin.com/players?page=624...\n",
      "Scraping https://futbin.com/players?page=625...\n",
      "Scraping https://futbin.com/players?page=626...\n",
      "Scraping https://futbin.com/players?page=627...\n",
      "Scraping https://futbin.com/players?page=628...\n",
      "Scraping https://futbin.com/players?page=629...\n",
      "Scraping https://futbin.com/players?page=630...\n",
      "Scraping https://futbin.com/players?page=631...\n",
      "Scraping https://futbin.com/players?page=632...\n",
      "Scraping https://futbin.com/players?page=633...\n",
      "Scraping https://futbin.com/players?page=634...\n",
      "Scraping https://futbin.com/players?page=635...\n",
      "Scraping https://futbin.com/players?page=636...\n",
      "Scraping https://futbin.com/players?page=637...\n",
      "Scraping https://futbin.com/players?page=638...\n",
      "Scraping https://futbin.com/players?page=639...\n",
      "Scraping https://futbin.com/players?page=640...\n",
      "Scraping https://futbin.com/players?page=641...\n",
      "Scraping https://futbin.com/players?page=642...\n",
      "Scraping https://futbin.com/players?page=643...\n",
      "Scraping https://futbin.com/players?page=644...\n",
      "Scraping https://futbin.com/players?page=645...\n",
      "Scraping https://futbin.com/players?page=646...\n",
      "Scraping https://futbin.com/players?page=647...\n",
      "Scraping https://futbin.com/players?page=648...\n",
      "Scraping https://futbin.com/players?page=649...\n",
      "Scraping https://futbin.com/players?page=650...\n",
      "Scraping https://futbin.com/players?page=651...\n",
      "Scraping https://futbin.com/players?page=652...\n",
      "Scraping https://futbin.com/players?page=653...\n",
      "Scraping https://futbin.com/players?page=654...\n",
      "Scraping https://futbin.com/players?page=655...\n",
      "Scraping https://futbin.com/players?page=656...\n",
      "Scraping https://futbin.com/players?page=657...\n",
      "Scraping https://futbin.com/players?page=658...\n",
      "Scraping https://futbin.com/players?page=659...\n",
      "Scraping https://futbin.com/players?page=660...\n",
      "Scraping https://futbin.com/players?page=661...\n",
      "Scraping https://futbin.com/players?page=662...\n",
      "Scraping https://futbin.com/players?page=663...\n",
      "Scraping https://futbin.com/players?page=664...\n",
      "Scraping https://futbin.com/players?page=665...\n",
      "Scraping https://futbin.com/players?page=666...\n",
      "Scraping https://futbin.com/players?page=667...\n",
      "Scraping https://futbin.com/players?page=668...\n",
      "Scraping https://futbin.com/players?page=669...\n",
      "Scraping https://futbin.com/players?page=670...\n",
      "Scraping https://futbin.com/players?page=671...\n",
      "Scraping https://futbin.com/players?page=672...\n",
      "Scraping https://futbin.com/players?page=673...\n",
      "Scraping https://futbin.com/players?page=674...\n",
      "Scraping https://futbin.com/players?page=675...\n",
      "Scraping https://futbin.com/players?page=676...\n",
      "Scraping https://futbin.com/players?page=677...\n",
      "Scraping https://futbin.com/players?page=678...\n",
      "Scraping https://futbin.com/players?page=679...\n",
      "Scraping https://futbin.com/players?page=680...\n",
      "Scraping https://futbin.com/players?page=681...\n",
      "Scraping https://futbin.com/players?page=682...\n",
      "Scraping https://futbin.com/players?page=683...\n",
      "Scraping https://futbin.com/players?page=684...\n",
      "Scraping https://futbin.com/players?page=685...\n",
      "Scraping https://futbin.com/players?page=686...\n",
      "Scraping https://futbin.com/players?page=687...\n",
      "Scraping https://futbin.com/players?page=688...\n",
      "Scraping https://futbin.com/players?page=689...\n",
      "Scraping https://futbin.com/players?page=690...\n",
      "Scraping https://futbin.com/players?page=691...\n",
      "Scraping https://futbin.com/players?page=692...\n",
      "Scraping https://futbin.com/players?page=693...\n",
      "Scraping https://futbin.com/players?page=694...\n",
      "Scraping https://futbin.com/players?page=695...\n",
      "Scraping https://futbin.com/players?page=696...\n",
      "Scraping https://futbin.com/players?page=697...\n",
      "Scraping https://futbin.com/players?page=698...\n",
      "Scraping https://futbin.com/players?page=699...\n",
      "Scraping https://futbin.com/players?page=700...\n",
      "Scraping https://futbin.com/players?page=701...\n",
      "Scraping https://futbin.com/players?page=702...\n",
      "Scraping https://futbin.com/players?page=703...\n",
      "Scraping https://futbin.com/players?page=704...\n",
      "Scraping https://futbin.com/players?page=705...\n",
      "Scraping https://futbin.com/players?page=706...\n",
      "Scraping https://futbin.com/players?page=707...\n",
      "Scraping https://futbin.com/players?page=708...\n",
      "Scraping https://futbin.com/players?page=709...\n",
      "Scraping https://futbin.com/players?page=710...\n",
      "Scraping https://futbin.com/players?page=711...\n",
      "Scraping https://futbin.com/players?page=712...\n",
      "Scraping https://futbin.com/players?page=713...\n",
      "Scraping https://futbin.com/players?page=714...\n",
      "Scraping https://futbin.com/players?page=715...\n",
      "Scraping https://futbin.com/players?page=716...\n",
      "Scraping https://futbin.com/players?page=717...\n",
      "Scraping https://futbin.com/players?page=718...\n",
      "Scraping https://futbin.com/players?page=719...\n",
      "Scraping https://futbin.com/players?page=720...\n",
      "Scraping https://futbin.com/players?page=721...\n",
      "Scraping https://futbin.com/players?page=722...\n",
      "Scraping https://futbin.com/players?page=723...\n",
      "Scraping https://futbin.com/players?page=724...\n",
      "Scraping https://futbin.com/players?page=725...\n",
      "Scraping https://futbin.com/players?page=726...\n",
      "Scraping https://futbin.com/players?page=727...\n",
      "Scraping https://futbin.com/players?page=728...\n",
      "Scraping https://futbin.com/players?page=729...\n",
      "Scraping https://futbin.com/players?page=730...\n",
      "Scraping https://futbin.com/players?page=731...\n",
      "Scraping https://futbin.com/players?page=732...\n",
      "Scraping https://futbin.com/players?page=733...\n",
      "Scraping https://futbin.com/players?page=734...\n",
      "Scraping https://futbin.com/players?page=735...\n",
      "Scraping https://futbin.com/players?page=736...\n",
      "Scraping https://futbin.com/players?page=737...\n",
      "Scraping https://futbin.com/players?page=738...\n",
      "Scraping https://futbin.com/players?page=739...\n",
      "Scraping https://futbin.com/players?page=740...\n",
      "Scraping https://futbin.com/players?page=741...\n",
      "Scraping https://futbin.com/players?page=742...\n",
      "Scraping https://futbin.com/players?page=743...\n",
      "Scraping https://futbin.com/players?page=744...\n",
      "Scraping https://futbin.com/players?page=745...\n",
      "Scraping https://futbin.com/players?page=746...\n",
      "Scraping https://futbin.com/players?page=747...\n",
      "Scraping https://futbin.com/players?page=748...\n",
      "Scraping https://futbin.com/players?page=749...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://futbin.com/players?page=750...\n",
      "Scraping https://futbin.com/players?page=751...\n",
      "Scraping https://futbin.com/players?page=752...\n",
      "Scraping https://futbin.com/players?page=753...\n",
      "Scraping https://futbin.com/players?page=754...\n"
     ]
    }
   ],
   "source": [
    "player_urls = []\n",
    "first_page = 'https://www.futbin.com/players?page=579'\n",
    "\n",
    "player_urls = scrape_player_urls(first_page, player_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving player URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5262"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(player_urls).to_csv('player_urls_xxx.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: reading HTML tables with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>RAT</th>\n",
       "      <th>POS</th>\n",
       "      <th>VER</th>\n",
       "      <th>PS</th>\n",
       "      <th>SKI</th>\n",
       "      <th>WF</th>\n",
       "      <th>WR</th>\n",
       "      <th>PAC</th>\n",
       "      <th>SHO</th>\n",
       "      <th>PAS</th>\n",
       "      <th>DRI</th>\n",
       "      <th>DEF</th>\n",
       "      <th>PHY</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>BS</th>\n",
       "      <th>IGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vegard Storsve</td>\n",
       "      <td>48</td>\n",
       "      <td>GK</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>M \\ M</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "      <td>185cm | 6'1\"  High &amp; Average+ (65kg)</td>\n",
       "      <td>6</td>\n",
       "      <td>278</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Huanhuan Shan</td>\n",
       "      <td>48</td>\n",
       "      <td>ST</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M \\ L</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>185cm | 6'1\"  High &amp; Average (75kg)</td>\n",
       "      <td>15</td>\n",
       "      <td>263</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lewis Collins</td>\n",
       "      <td>48</td>\n",
       "      <td>CM</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M \\ L</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>52</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>178cm | 5'10\"  Lean (67kg)</td>\n",
       "      <td>5</td>\n",
       "      <td>284</td>\n",
       "      <td>1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guobo Liu</td>\n",
       "      <td>48</td>\n",
       "      <td>CM</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>L \\ L</td>\n",
       "      <td>63</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "      <td>189cm | 6'2\"  High &amp; Average (75kg)</td>\n",
       "      <td>10</td>\n",
       "      <td>288</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peng Wang</td>\n",
       "      <td>48</td>\n",
       "      <td>CAM</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1K</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>M \\ M</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>175cm | 5'9\"  Average (70kg)</td>\n",
       "      <td>9</td>\n",
       "      <td>275</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name  RAT  POS     VER   PS  SKI  WF     WR  PAC  SHO  PAS  DRI  \\\n",
       "0  Vegard Storsve   48   GK  Normal  200    1   2  M \\ M   50   50   48   51   \n",
       "1   Huanhuan Shan   48   ST  Normal  200    2   3  M \\ L   58   43   35   49   \n",
       "2   Lewis Collins   48   CM  Normal  200    2   3  M \\ L   70   40   46   52   \n",
       "3       Guobo Liu   48   CM  Normal  200    2   2  L \\ L   63   38   45   48   \n",
       "4       Peng Wang   48  CAM  Normal   1K    2   3  M \\ M   60   34   51   48   \n",
       "\n",
       "   DEF  PHY                           Unnamed: 14  Unnamed: 15   BS   IGS  \n",
       "0   30   49  185cm | 6'1\"  High & Average+ (65kg)            6  278   538  \n",
       "1   30   48   185cm | 6'1\"  High & Average (75kg)           15  263  1181  \n",
       "2   38   38            178cm | 5'10\"  Lean (67kg)            5  284  1308  \n",
       "3   41   53   189cm | 6'2\"  High & Average (75kg)           10  288  1372  \n",
       "4   36   46          175cm | 5'9\"  Average (70kg)            9  275  1321  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_table = pd.read_html(res.text)[0]\n",
    "html_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Side note: making things faster with Scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
